# Procesamiento

## Identificaci√≥n y eliminaci√≥n de duplicados

La Tabla \@ref(tab:tabla-duplicados) muestra la cantidad de datos originales, la cantidad de de filas duplicadas y el porcentaje de filas duplicadas del conjunto de datos.


```{r tabla-duplicados, eval=TRUE, echo=FALSE}
# Identificamos los duplicados
total_datos <- nrow(datos_raw)
duplicados <- duplicated(datos_raw)
total_duplicados <- sum(duplicados)

# Eliminar duplicados
datos <- datos_raw[!duplicados, ]

# Tabla con informaci√≥n de duplicados en formato vertical
resumen_duplicados <- data.frame(
  Concepto = c(
    "Total de datos original",
    "Total de duplicados",
    "Porcentaje de duplicados (%)",
    "Total de datos sin duplicados"
  ),
  Valor = c(
    nrow(datos_raw),
    total_duplicados,
    paste(round(total_duplicados/nrow(datos_raw)  * 100, 2), "%"),
    nrow(datos)
  )
)
# danmos formato a la tabla de reporte de duplicados
knitr::kable(
  resumen_duplicados,
  caption = "Detecci√≥n y eliminaci√≥n de duplicados",
  label = "tabla-duplicados",
  col.names = c("Concepto", "Valor"),
  align = c("l", "l")
)

# guardamos los datos sin duplicados en un csv
write.csv(datos, "data/procesados/sin_duplicados.csv", row.names = FALSE)
```
Se identificaron **`r total_duplicados`** registros duplicados (representando el **`r round(total_duplicados/nrow(datos_raw)*100, 2)`%** del total). Estos corresponden a clientes con informaci√≥n id√©ntica en todas las variables. La presencia de duplicados introduce sesgo en los estimadores de tendencia central y dispersi√≥n, inflando artificialmente el tama√±o muestral y violando el supuesto de independencia. Seg√∫n Barnett y Lewis (1994), duplicados exactos deben eliminarse antes del an√°lisis para evitar sobreponderaci√≥n de observaciones particulares. 

```{r datos-sin-duplicados, echo=FALSE}
#cargamos los datos sin duplicados
datos_sin_duplicados <- read.csv("data/procesados/sin_duplicados.csv")
```

## Errores e inconsistencias

En la Tabla \@ref(tab:tabla-est-desc) se muestran las principales estadisticas descriptivas para las variables continuas y discretas

```{r tabla-est-desc, echo=FALSE}
#Variables num√©ricas para an√°lisis
vars_objetivo <- c("Income", "MntWines","MntFruits", "MntMeatProducts",
                   "MntFishProducts","MntSweetProducts", "MntGoldProds",
                   "MntTotal","MntRegularProds", "Kidhome", "Teenhome",
                   "Recency","NumDealsPurchases","NumWebPurchases",
                   "NumCatalogPurchases","NumStorePurchases",
                   "NumWebVisitsMonth", "Age", "Customer_Days")
# Funci√≥n para calculae¬ør estadisticps descriptivos
detectar_atipicos_iqr <- function(x) {
  Min = min(x, na.rm = TRUE)
  Max = max(x, na.rm = TRUE)
  Media = mean(x, na.rm = TRUE)
  std = sd(x, na.rm = TRUE)
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Mediana = median(x, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lim_inf <- Q1 - 1.5 * IQR
  lim_sup <- Q3 + 1.5 * IQR
  atipicos <- x < lim_inf | x > lim_sup
  
  list(
    Min = Min,
    Media = Media,
    std = std,
    Q1 = Q1,
    Mediana = Mediana,
    Q3 = Q3,
    Max = Max,
    IQR = IQR,
    lim_inf = lim_inf,
    lim_sup = lim_sup,
    n_atipicos = sum(atipicos, na.rm = TRUE),
    porcentaje = sum(atipicos, na.rm = TRUE) / sum(!is.na(x)) * 100
  )
}

# Aplicar a todas las variables
resultados_lista <- lapply(vars_objetivo, function(var) {
  if (var %in% colnames(datos)) {
    resultado <- detectar_atipicos_iqr(datos[[var]])
    data.frame(
      Variable = var,
      Min = round(resultado$Min, 1),
      Media = round(resultado$Media, 1),
      std = round(resultado$std, 1),
      Q1 = round(resultado$Q1, 1),
      Mediana = round(resultado$Mediana, 1),
      Q3 = round(resultado$Q3, 1),
      Max = round(resultado$Max, 1),
      lim_inf = round(resultado$lim_inf, 1),
      lim_sup = round(resultado$lim_sup, 1),
      IQR = round(resultado$IQR, 1),
      N_atipicos = resultado$n_atipicos,
      Porcentaje = round(resultado$porcentaje, 1)
    )
  }
})

# Combinar la lista en un data frame
tabla_estadisticos <- do.call(rbind, resultados_lista)

# Estad√≠sticos descriptivos
tabla_estadisticos <- tabla_estadisticos[, c("Variable", "Min", "Media", 
                                           "std", "Q1","Mediana", "Q3", "Max")]

knitr::kable(
  tabla_estadisticos,
  caption = "Estad√≠sticos descriptivos y l√≠mites IQR",
  col.names = c("Variable", "M√≠n", "Media","std", "Q1", "Mediana","Q3", 
                "M√°x"),
  align = c("l", "l", "l", "l", "l", "l", "l", "l"),
  row.names = FALSE
)

```

La Tabla \@ref(tab:total-porcentaje-atipicos) muestra la detecci√≥n de valores at√≠picos mediante el m√©todo **IQR** (rango intercuart√≠lico Tukey, 1977) el cual es una medida de dispersi√≥n robusta que cuantifica la amplitud del $50 \%$ central de la distribuci√≥n, con l√≠mites definidos como:

$$IQR = Q_3 - Q_1$$ 
 

$$L_{inf} = Q_1 - (1.5 \cdot IQR)$$
$$L_{sup} =  Q_3 + (1.5 \cdot IQR)$$

Un valor $x$ es at√≠pico si:

$$ùë• <  L_{inf} = Q_1 - (1.5 \cdot IQR) \quad \text{o} \quad x > L_{sup} = Q_3 + (1.5 \cdot IQR)$$


```{r total-porcentaje-atipicos, echo=FALSE}
tabla_atipicos <- do.call(rbind, resultados_lista)
# At√≠picos
tabla_atipicos_resumen <- tabla_atipicos[, c("Variable", "lim_inf", "lim_sup", "IQR", "N_atipicos", "Porcentaje")]

knitr::kable(
  tabla_atipicos_resumen,
  caption = "Resumen de total valores at√≠picos detectados",
  col.names = c("Variable", "lim_inf", "lim_sup", "IQR","N¬∞ at√≠picos", "% at√≠picos"),
  align = c("l", "r", "r", "r", "r", "r"),
  row.names = FALSE
)
```


### Visualizaci√≥n de distribuciones 

#### Boxplot para cada variable continua

```{r boxplotcontinuas, echo=FALSE, fig.cap="Distribuci√≥n de variables num√©ricas continuas", echo=FALSE}

vars_numericas_continuas <- c("Income", "MntWines","MntFruits", "MntMeatProducts",
                              "MntFishProducts","MntSweetProducts", "MntGoldProds",
                              "MntTotal","MntRegularProds")

datos_largo <- datos %>%
  select(all_of(vars_numericas_continuas)) %>%
  pivot_longer(cols = everything(), 
               names_to = "Variable", 
               values_to = "Valor")

ggplot(datos_largo, aes(x = Variable, y = Valor, fill = Variable)) +
  geom_boxplot(outlier.color = "firebrick", outlier.size = 1) +
  facet_wrap(~ Variable, scales = "free", ncol = 3) +
  scale_fill_brewer(palette = "Dark2") +
  theme_minimal() +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none",
    strip.text = element_text(face = "bold", size = 10)
  ) +
  labs(
    title = "Distribuci√≥n de variables monetarias continuas",
    x = "",
    y = "Valor"
  )
```

De acuerpo con los boxplots de la figura \@ref(fig:boxplotcontinuas) podemos resaltar:

- **Income:** Distribuci√≥n asim√©trica positiva (sesgo derecho) con mediana ‚âà $52,000. At√≠picos superiores representan clientes de muy alto ingreso (segmento premium).
- **MntWines:** Mayor variabilidad en gasto. Categor√≠a con mayor consumo promedio.
- **MntFruits, MntFish, MntSweet, MntGold:** Cajas comprimidas cerca de cero. Mayor√≠a gasta poco; at√≠picos superiores indican compradores especializados.
- **MntTotal y MntRegularProds:** Alta correlaci√≥n esperada. Dispersi√≥n amplia refleja heterogeneidad en comportamiento de compra.


#### Estudio de las variables discretas

```{r boxplot-discretas, fig.cap="Boxplots de variables num√©ricas discretas", echo=FALSE}

vars_numericas_discretas <- c("Kidhome", "Teenhome", "Recency", "NumDealsPurchases",
                              "NumWebPurchases","NumCatalogPurchases","NumStorePurchases",
                              "NumWebVisitsMonth", "Age", "Customer_Days")

datos_largo_disc <- datos %>%
  select(all_of(vars_numericas_discretas)) %>%
  pivot_longer(cols = everything(), 
               names_to = "Variable", 
               values_to = "Valor")

ggplot(datos_largo_disc, aes(x = "", y = Valor, fill = Variable)) +
  geom_boxplot(outlier.color = "firebrick", outlier.size = 1) +
  facet_wrap(~ Variable, scales = "free_y", ncol = 3) +
  scale_fill_brewer(palette = "Dark2") +
  theme_minimal() +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    legend.position = "none",
    strip.text = element_text(face = "bold", size = 11)
  ) +
  labs(
    title = "Distribuci√≥n de variables num√©ricas discretas",
    x = "",
    y = "Valor"
  )
```

La Figura \@ref(fig:boxplot-discretas) muestra la distribuci√≥n de variables num√©ricas discretas. De donde podemos resaltar

- **Age:** Presencia de at√≠picos superiores (>80 a√±os) requiere validaci√≥n.
- **NumStorePurchases:** Canal preferido (mediana ‚âà 5-6), distribuci√≥n sim√©trica.
- **NumWebPurchases:** Adopci√≥n moderada del canal digital.
- **Kidhome/Teenhome:** Mayor√≠a sin dependientes (mediana = 0).
- **Customer_Days:** Alta antig√ºedad promedio 2511 d√≠as ‚âà 6.9 a√±os, indicando lealtad.



#### Estudio de variables binarias

La Figura \@ref(fig:barras-binarias) muestra la distribuci√≥n de frecuencias para variables categ√≥ricas binarias.

```{r barras-binarias, fig.cap="Distribuci√≥n de variables binarias", fig.width=12, fig.height=16, , echo=FALSE}
vars_binarias <- c("AcceptedCmp1", "AcceptedCmp2","AcceptedCmp3","AcceptedCmp4",
                   "AcceptedCmp5","Response","Complain","marital_Divorced",
                   "marital_Married","marital_Single","marital_Together",
                   "marital_Widow", "education_2n Cycle", "education_Basic",
                   "education_Graduation", "education_Master", "education_PhD")

lista_graficos <- lapply(seq_along(vars_binarias), function(i) {
  var <- vars_binarias[i]
  
  tabla_freq <- datos %>%
    count(!!sym(var)) %>%
    rename(Categoria = 1, Frecuencia = n) %>%
    mutate(Categoria = factor(Categoria, levels = c(0, 1), labels = c("No", "S√≠")))
  
  ggplot(tabla_freq, aes(x = Categoria, y = Frecuencia, fill = Categoria)) +
    geom_bar(stat = "identity", alpha = 0.85, show.legend = FALSE) +
    geom_text(aes(label = Frecuencia), vjust = -0.5, size = 4, fontface = "bold") +
    #scale_fill_manual(values = c("No" = "red", "S√≠" = "green")) +
    scale_fill_brewer(palette = "Dark2")+
    theme_minimal() +
    theme(
      axis.text.x = element_text(size = 10, face = "bold"),
      plot.title = element_text(face = "bold", size = 10, hjust = 0.5),
      panel.grid.major.x = element_blank()
    ) +
    labs(title = var, x = "", y = "Frecuencia") +
    ylim(0, max(tabla_freq$Frecuencia) * 1.15)
})

do.call(grid.arrange, c(lista_graficos, ncol = 4))
```

De la figura  \@ref(fig:barras-binarias) podemos podemos resaltar

- **Campa√±as de marketing:** Tasa de aceptaci√≥n menor al **15\%** en todas las campa√±as, sugiriendo problema estructural de efectividad.
- **Perfil demogr√°fico:** Predominio de clientes casados entre el **35\%** y *40\%*, con educaci√≥n superior aproximadamente del **70\%**.
- **Quejas:** Frecuencia muy baja menos del **5\%**, indicando satisfacci√≥n general.
- **Desbalance de clases:** Variable objetivo (Response) presenta desbalance **85:15**, implicaci√≥n para modelado predictivo futuro.



## An√°lisis de datos at√≠picos

Los valores at√≠picos observados en variables de gasto como por ejemplo, *MntTotal *, *MntWines* y otras variables monetarias ser√°n conservados, ya que representan el segmento *premium* de clientes de alto valor. Seg√∫n Rousseeuw y Hubert (2011), valores at√≠picos en el dominio natural de la variable deben conservarse cuando reflejan heterogeneidad real del fen√≥meno estudiado. Eliminarlos sesgar√≠a la estimaci√≥n del potencial de ingresos y reducir√≠a artificialmente la varianza poblacional.

Por otro lado, los valores extremos en variables de comportamiento como *NumWebVisitsMonth* o *NumDealsPurchases* tambi√©n se mantendr√°n, dado que reflejan patrones aut√©nticos de uso intensivo o baja interacci√≥n, los cuales son relevantes para la segmentaci√≥n y el modelado predictivo. En s√≠ntesis, se eliminar√°n √∫nicamente observaciones inconsistentes desde el punto de vista l√≥gico y/o biol√≥gico, mientras que se conservaron aquellas que, aunque extremas, representan comportamientos reales y econ√≥micamente significativos dentro de la poblaci√≥n analizada.

 
#### Revisi√≥n en detalle de inconsistencias 
Se detectaron inconsistencias estructurales en las variables **MntRegularProds**, **Age** y **marital_Divorced** comos e muestra en la Tabla \@ref(tab:tabla-inconsistencias). En el caso de **MntRegularProds** se identificaron *valores negativos*, los cuales violan el dominio te√≥rico de la variable (monto ‚â• 0). En **Age** se observaron registros con valor **240**, imposible desde el punto de vista biol√≥gico.L√≠mite superior razonable: 110 a√±os (r√©cord mundial: 122 a√±os, Jeanne Calment). Asimismo, **marital_Divorced** present√≥ valores distintos de **0** y **1**, lo que viola la naturaleza binaria.

```{r tabla-inconsistencias, echo=FALSE}
inconsistencias <- tibble(
  Variable = c("MntRegularProds", "Age", "marital_Divorced"),
  Criterio_validez = c(
    "Monto ‚â• 0",
    "0 < Edad ‚â§ 110 a√±os",
    "Valor ‚àà {0, 1}"
  ),
  Registros_invalidos = c(
    sum(datos$MntRegularProds < 0, na.rm = TRUE),
    sum(datos$Age <= 0 | datos$Age > 110, na.rm = TRUE),
    sum(!datos$marital_Divorced %in% c(0,1), na.rm = TRUE)
  ),
  Valores_detectados = c(
    paste(unique(datos$MntRegularProds[datos$MntRegularProds < 0]), collapse = ", "),
    paste(unique(datos$Age[datos$Age <= 0 | datos$Age > 110]), collapse = ", "),
    paste(unique(datos$marital_Divorced[!datos$marital_Divorced %in% c(0,1)]), collapse = ", ")
  )
)

knitr::kable(
  inconsistencias,
  caption = "Inconsistencias estructurales detectadas",
  col.names = c("Variable", "Criterio de validez", "N¬∞ inv√°lidos", "Valores detectados"),
  align = c("l", "l", "c", "l")
)
```

La Tabla \@ref(tab:tabla-inconsistencias) documenta las inconsistencias estructurales detectadas.

## Tratamiento de inconsistencias
Seg√∫n Osborne y Overbay (2004), inconsistencias que violan restricciones del dominio deben eliminarse por completo, ya que no admiten correcci√≥n sin introducir mayor incertidumbre.


```{r eliminar-inconsistencias, echo=FALSE}
datos_limpios <- datos %>%
  filter(
    MntRegularProds >= 0,
    Age > 0 & Age <= 110,
    marital_Divorced %in% c(0,1)
  )

n_eliminados <- nrow(datos) - nrow(datos_limpios)
pct_eliminados <- round(n_eliminados / nrow(datos) * 100, 2)
```

```{r, include=FALSE, echo=FALSE}
# guardamos los datos sin duplicados en un csv
write.csv(datos_limpios, "data/procesados/datos_limpios.csv", row.names = FALSE)
```

Tras la eliminaci√≥n de registros duplicados, la base qued√≥ compuesta por *2.041* registros.
Se eliminaron **`r n_eliminados`** registros (**`r pct_eliminados`%** del total de los *2.041*), que presentaban inconsistencias estructurales: valores negativos en MntRegularProds, edades imposibles (*240 a√±o*s) y codificaciones inv√°lidas en marital_Divorced (valor *100*). Dado que estas observaciones violan el dominio te√≥rico de las variables y representan una proporci√≥n marginal de la muestra, se opt√≥ por su eliminaci√≥n completa. Resultando en **`r nrow(datos_limpios)`** observaciones v√°lidas.

La Tabla \@ref(tab:mntregula-Age-antes-despues) muestra el impacto del tratamiento en indicadores descriptivos.

```{r mntregula-Age-antes-despues, echo=FALSE}
# Antes
resumen_antes <- datos %>%
  summarise(
    across(c(MntRegularProds, Age), 
           list(
             Media = ~mean(., na.rm = TRUE),
             Mediana = ~median(., na.rm = TRUE),
             DE = ~sd(., na.rm = TRUE),
             Q1 = ~quantile(., 0.25, na.rm = TRUE),
             Q3 = ~quantile(., 0.75, na.rm = TRUE)
           ))
  ) %>%
  pivot_longer(everything(), 
               names_to = c("Variable", "Estadistica"),
               names_sep = "_",
               values_to = "Valor") %>%
  pivot_wider(names_from = Estadistica, values_from = Valor) %>%
  mutate(Momento = "Antes")

# Despu√©s
resumen_despues <- datos_limpios %>%
  summarise(
    across(c(MntRegularProds, Age), 
           list(
             Media = ~mean(., na.rm = TRUE),
             Mediana = ~median(., na.rm = TRUE),
             DE = ~sd(., na.rm = TRUE),
             Q1 = ~quantile(., 0.25, na.rm = TRUE),
             Q3 = ~quantile(., 0.75, na.rm = TRUE)
           ))
  ) %>%
  pivot_longer(everything(), 
               names_to = c("Variable", "Estadistica"),
               names_sep = "_",
               values_to = "Valor") %>%
  pivot_wider(names_from = Estadistica, values_from = Valor) %>%
  mutate(Momento = "Despu√©s")

# Combinar
comparacion <- bind_rows(resumen_antes, resumen_despues) %>%
  select(Momento, Variable, everything()) %>%
  arrange(Variable, Momento)

knitr::kable(
  comparacion,
  digits = 2,
  caption = "Comparaci√≥n de indicadores descriptivos antes y despu√©s del tratamiento",
  align = c("l", "l", "r", "r", "r", "r", "r")
)
```


Para la variable **MntRegularProds**, seg√∫n la Tabla \@ref(tab:mntregula-Age-antes-despues), - Media aumenta ligeramente de **520.59** a **522.72**, es decir, un incremento de **2.13** unidades (**‚âà 0.4\%**). En t√©rminos relativos, el cambio es despreciable. 
- La mediana pasa de **288.0** a **290.5**, lo que confirma que la posici√≥n central robusta pr√°cticamente no se altera. 
- La desviaci√≥n est√°ndar se mantiene esencialmente constante **555.80** frente a **555.82** (**‚âà0.04\%**).
- Los cuartiles $Q_1$ y $Q_3$ presentan variaciones m√≠nimas.

Esto indica que la dispersi√≥n intercuart√≠lica permanece estable. La Figura \@ref(fig:comp-boxplots) corrobora visualmente este comportamiento: los boxplots antes y despu√©s del tratamiento presentan estructura y rango intercuart√≠lico pr√°cticamente id√©nticos.

En consecuencia, la eliminaci√≥n de los tres valores negativos no modific√≥ de manera sustancial los indicadores de tendencia central ni de dispersi√≥n. Dichas observaciones, aunque inconsistentes desde el punto de vista l√≥gico, no ejerc√≠an influencia relevante sobre la estructura estad√≠stica global de la variable.


Para la variable **Age**, la Tabla \@ref(tab:mntregula-Age-antes-despues) muestran que
- La media disminuye de **51.35** a **51.17** (**‚âà0.35\%**). Esto indica que los registros con edad 240 inflaban ligeramente el promedio. 

- La mediana permanece exactamente en **50**, lo que confirma que el valor extremo no afectaba la posici√≥n central robusta.

- La desviaci√≥n est√°ndar disminuye de **13.04** a **11.65**, lo que representa una reducci√≥n relativa aproximada del **10.6\%**. Este cambio evidencia que el registro con edad 240 generaba una sobreestimaci√≥n apreciable de la variabilidad. 

- Los cuartiles $Q_1$ y $Q_3$ no presentan modificaciones, por lo que la dispersi√≥n intercuart√≠lica se mantiene estable.

La Figura \@ref(fig:comp-boxplots) respalda este an√°lisis: el boxplot posterior al tratamiento muestra una reducci√≥n clara en la amplitud total, mientras que la caja central conserva su posici√≥n y tama√±o.

Por tanto, la eliminaci√≥n del valor at√≠pico produjo una disminuci√≥n significativa en la desviaci√≥n est√°ndar, corrigiendo la sobreestimaci√≥n de la variabilidad, pero sin alterar la estructura central de la distribuci√≥n.

```{r comp-boxplots, fig.width=12, fig.height=5, fig.cap="Comparaci√≥n de distribuciones antes (rojo) y despu√©s (azul) del tratamiento de inconsistencias.", echo=FALSE}
# MntRegularProds
p1 <- ggplot() +
  geom_boxplot(data = datos, aes(x = "Antes", y = MntRegularProds), 
               fill = "#E74C3C", alpha = 0.8) +
  geom_boxplot(data = datos_limpios, aes(x = "Despu√©s", y = MntRegularProds), 
               fill = "#3498DB", alpha = 0.8) +
  labs(title = "MntRegularProds", y = "Valor", x = "") +
  theme_minimal()

# Age
p2 <- ggplot() +
  geom_boxplot(data = datos, aes(x = "Antes", y = Age), 
               fill = "#E74C3C", alpha = 0.8) +
  geom_boxplot(data = datos_limpios, aes(x = "Despu√©s", y = Age), 
               fill = "#3498DB", alpha = 0.8) +
  labs(title = "Age", y = "Edad (a√±os)", x = "") +
  theme_minimal()

grid.arrange(p1, p2, ncol = 2)
```



Para una variable binaria como marital_Divorced, lo adecuado es una tabla de distribuci√≥n de frecuencias absoluta y relativa, incluyendo proporciones.

```{r marital-divorced-antes, echo=FALSE}
tabla_marital <- datos_sin_duplicados %>%
  count(marital_Divorced) %>%
  mutate(
    Porcentaje = round(100 * n / sum(n), 2)
  ) %>%
  rename(
    Categoria = marital_Divorced,
    Frecuencia = n
  )

knitr::kable(
  tabla_marital,
  caption = "Distribuci√≥n de la variable binaria marital_Divorced antes del tratamiento.",
  label = "marital-divorced-antes",
  col.names = c("Categor√≠a (0 = No divorciado, 1 = Divorciado, 100 = Inconsistencia)",
                "Frecuencia",
                "Porcentaje (%)"),
  align = c("c", "c", "c")
)
```

```{r marital-divorced-despues, echo=FALSE}
tabla_marital <- datos_limpios %>%
  count(marital_Divorced) %>%
  mutate(
    Porcentaje = round(100 * n / sum(n), 2)
  ) %>%
  rename(
    Categoria = marital_Divorced,
    Frecuencia = n
  )

knitr::kable(
  tabla_marital,
  caption = "Distribuci√≥n de la variable binaria marital_Divorced despu√©s del tratamiento.",
  label = "marital-divorced-despues",
  col.names = c("Categor√≠a (0 = No divorciado, 1 = Divorciado)",
                "Frecuencia",
                "Porcentaje (%)"),
  align = c("c", "c", "c")
)
```

```{r tabla-marital, echo=FALSE, include=FALSE}
tabla_marital_comp <- bind_rows(
  datos %>%
    mutate(Momento = "Antes") %>%
    count(Momento, marital_Divorced) %>%
    group_by(Momento) %>%
    mutate(Porcentaje = round(100 * n / sum(n), 2)),
  
  datos_limpios %>%
    mutate(Momento = "Despu√©s") %>%
    count(Momento, marital_Divorced) %>%
    group_by(Momento) %>%
    mutate(Porcentaje = round(100 * n / sum(n), 2))
) %>%
  ungroup()

knitr::kable(
  tabla_marital_comp,
  caption = "Distribuci√≥n de marital_Divorced antes y despu√©s del tratamiento",
  col.names = c("Momento", "Categor√≠a", "Frecuencia", "Porcentaje (%)"),
  align = c("l", "c", "r", "r")
)
```

```{r barras-marital-divorced-comparacion, fig.width=12, fig.height=5, fig.cap="Comparaci√≥n de la distribuci√≥n de marital_Divorced antes y despu√©s del tratamiento.", echo=FALSE}
ggplot(tabla_marital_comp,
       aes(x = factor(marital_Divorced),
           y = Porcentaje,
           fill = Momento)) +
  scale_fill_brewer(palette = "Dark2") +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = Porcentaje),
            position = position_dodge(width = 0.9),
            vjust = -0.5,
            size = 3.5) +
  labs(
    x = "",
    y = "Porcentaje",
    fill = "Momento"
  ) +
  theme_minimal()
```

Antes del tratamiento se identificaron **6** registros con valor **100** como se observa en la Tabla \@ref(tab:marital-divorced-antes) , correspondiente al **0.29\%** del total de las **2041** observaciones. Tras su eliminaci√≥n, la estructura porcentual de la variable pr√°cticamente no se modific√≥ como se puede observar en la Tabla \@ref(tab:marital-divorced-despues) , lo cual indica que la inconsistencia no afectaba sustancialmente la distribuci√≥n de la variable, lo cual es m√°s evidente en la gr√°fica de la figura \@ref(fig:barras-marital-divorced-comparacion).



### Validaci√≥n y evaluaci√≥n de la depuraci√≥n

La principal preocupaci√≥n al eliminar registros es introducir un sesgo, alterando la estructura subyacente de los datos. Vamos a resposnder a la sigyuiente pregunta

¬øLa eliminaci√≥n de duplicados e inconsistentes ha sido una decisi√≥n metodol√≥gicamente s√≥lida y, por lo tanto, podemos proceder con confianza al tratamiento de los valores faltantes en el conjunto de datos de 2030 registros?

```{r muestra-original-limpios, echo=FALSE}
tabla_tamano <- data.frame(
  n_original = nrow(datos_raw),
  n_limpios = nrow(datos_limpios)
)

tabla_tamano$Eliminados <- tabla_tamano$n_original - tabla_tamano$n_limpios
tabla_tamano$Porcentaje_eliminado <- 
  round(tabla_tamano$Eliminados / tabla_tamano$n_original * 100, 3)

knitr::kable(
  tabla_tamano,
  caption = "Comparaci√≥n del tama√±o muestral antes y despu√©s de eliminar inconsistencias",
  col.names = c("N original", "N limpio", "Registros eliminados", "% eliminado"),
  align = "c"
)

```


```{r esta-desc-original-limpios, echo=FALSE}
comparar_estadisticos <- function(var){
  data.frame(
    Variable = var,
    Media_original = mean(datos_raw[[var]], na.rm=TRUE),
    Media_limpios  = mean(datos_limpios[[var]], na.rm=TRUE),
    SD_original = sd(datos_raw[[var]], na.rm=TRUE),
    SD_limpios  = sd(datos_limpios[[var]], na.rm=TRUE),
    Mediana_original = median(datos_raw[[var]], na.rm=TRUE),
    Mediana_limpios  = median(datos_limpios[[var]], na.rm=TRUE)
  )
}

vars <- vars_numericas_continuas

tabla_comparacion <- do.call(rbind, lapply(vars, comparar_estadisticos))

tabla_comparacion$Cambio_relativo_media <- round(
  abs(tabla_comparacion$Media_original - tabla_comparacion$Media_limpios) /
  abs(tabla_comparacion$Media_original) * 100, 3
)

knitr::kable(
  tabla_comparacion,
  caption = "Comparaci√≥n de estad√≠sticos descriptivos antes y despu√©s de la depuraci√≥n",
  align = "l",
  digits = 3
)

```


```{r prueba-KS, echo=FALSE}
tabla_ks <- do.call(rbind, lapply(vars, function(var){
  test <- ks.test(
    datos_raw[[var]][!is.na(datos_raw[[var]])],
    datos_limpios[[var]][!is.na(datos_limpios[[var]])]
  )
  
  data.frame(
    Variable = var,
    Estadistico_D = round(test$statistic, 4),
    p_value = round(test$p.value, 4)
  )
}))

knitr::kable(
  tabla_ks,
  caption = "Prueba de Kolmogorov‚ÄìSmirnov para igualdad de distribuciones",
  align = "c"
)

```


```{r prueba-Frobenius, echo=FALSE}
R_original <- cor(datos_raw[vars], use="complete.obs")
R_limpios  <- cor(datos_limpios[vars], use="complete.obs")

norma_frobenius <- sqrt(sum((R_original - R_limpios)^2))

tabla_cor <- data.frame(
  Norma_Frobenius = round(norma_frobenius, 6)
)

knitr::kable(
  tabla_cor,
  caption = "Diferencia global entre matrices de correlaci√≥n (Norma de Frobenius)",
  align = "c"
)

```

En la Tabla \@ref(tab:esta-desc-original-limpios) es crucial observar que las medias, desviaciones est√°ndar y medianas de todas las variables permanecen pr√°cticamente id√©nticas. Por ejemplo, la media de **Income** pasa de **516,535** a **517,963**, un cambio de apenas **0.27\%**. La desviaci√≥n est√°ndar tambi√©n se mantiene estable. En t√©rminos estad√≠sticos, esto indica que la localizaci√≥n y la escala de las distribuciones no se han visto afectadas. La estructura central de los datos es la misma.

La Tabla \@ref(tab:prueba-KS) muestra la evidencia m√°s s√≥lida. La **prueba KS** es una herramienta no param√©trica poderosa para comparar distribuciones completas. Los **estad√≠sticos D** (que miden la distancia m√°xima entre las distribuciones acumuladas) son extremadamente bajos por ejemplo, **0.0065** para **Income**, y los **p-values** son exactamente **1**, lo que cnfirma no existe evidencia estad√≠stica que sugiera que las distribuciones, antes y despu√©s de la limpieza, sean diferentes. Son, a efectos pr√°cticos, id√©nticas.


En la Tabla \@ref(tab:prueba-Frobenius) la norma de Frobenius cuantifica la diferencia global entre dos matrices. Un valor de **0.0558** es extraordinariamente bajo. Esto significa que las relaciones lineales entre las variables se han mantenido casi inalteradas. La estructura de correlaci√≥n, que es la "anatom√≠a" de las relaciones entre variables, sigue siendo la misma.

En resumen, la eliminaci√≥n del **8.56%** de los datos (190 registros, Tabla \@ref(tab:muestra-original-limpios)) ha sido un proceso de limpieza efectivo. No ha introducido sesgo ni ha alterado las propiedades estad√≠sticas fundamentales del conjunto de datos. Hemos eliminado ruido (duplicados e inconsistencias) conservando la esencia de la informaci√≥n, lo que valida metodol√≥gicamente el uso del conjunto depurado de 
**2030** observaciones para el posterior tratamiento de valores faltantes.


## Identificaci√≥n de datos faltantes

```{r tabla-nulos-original, echo=FALSE}
tabla_nulos <- data.frame(
  Variable = names(datos_raw),
  Nulos = colSums(is.na(datos_raw)),
  Porcentaje = round(colSums(is.na(datos_raw)) / nrow(datos_raw) * 100, 2)
) %>%
  filter(Nulos > 0) %>%
  arrange(desc(Porcentaje))

knitr::kable(
  tabla_nulos,
  caption = "Datos faltantes (solo variables con NA del dataset original)",
  col.names = c("Variable", "Cantidad NA", "Porcentaje (%)"),
  align = c("l", "r", "r"),
  row.names = FALSE
)
```

```{r tabla-nulos-sin-duplicados, echo=FALSE}
tabla_nulos <- data.frame(
  Variable = names(datos_sin_duplicados),
  Nulos = colSums(is.na(datos_sin_duplicados)),
  Porcentaje = round(colSums(is.na(datos_sin_duplicados)) / nrow(datos_sin_duplicados) * 100, 2)
) %>%
  filter(Nulos > 0) %>%
  arrange(desc(Porcentaje))

knitr::kable(
  tabla_nulos,
  caption = "Datos faltantes (solo variables con NA del dataset sin duplicados)",
  col.names = c("Variable", "Cantidad NA", "Porcentaje (%)"),
  align = c("l", "r", "r"),
  row.names = FALSE
)
```

Para el conjunto de datos sin  duplicados  y sin inconsistentes, procedemos a dentificamos las variables con valores nulos o faltante.

```{r tabla-nulos, echo=FALSE}
tabla_nulos <- data.frame(
  Variable = names(datos_limpios),
  Nulos = colSums(is.na(datos_limpios)),
  Porcentaje = round(colSums(is.na(datos_limpios)) / nrow(datos_limpios) * 100, 2)
) %>%
  filter(Nulos > 0) %>%
  arrange(desc(Porcentaje))

knitr::kable(
  tabla_nulos,
  caption = "Datos faltantes (solo variables con NA)",
  col.names = c("Variable", "Cantidad NA", "Porcentaje (%)"),
  align = c("l", "r", "r"),
  row.names = FALSE
)
```

La  Figura \@ref(fig:fig-datos-faltantes) se presenta un resumen de las variables ordenadas seg√∫n el n√∫mero de datos faltantes.

```{r fig-datos-faltantes, eval=TRUE,fig.cap="Porcentaje de datos faltantes por variables y combinaciones de faltantes por variables.", echo=FALSE,fig.width=10, fig.height=8}
# Ajuste de m√°rgenes: inferior, izquierda, superior y derecha
par(mar = c(6, 4, 2, 2) + 0.1)

# Gr√°fico de patrones de missing con n√∫meros
VIM::aggr(
  datos_limpios,
  palette = "Dark2",  # colores: presente / faltante
  numbers     = TRUE,                     # muestra el n√∫mero de casos
  prop        = FALSE,                    # FALSE = muestra conteos, TRUE = proporciones
  cex.numbers = 0.8,                      # tama√±o de los n√∫meros
  sortVars    = TRUE,                     # ordena variables por % de missing
  labels      = names(datos_limpios),        # etiquetas para el eje X
  cex.axis    = 0.7,                      # tama√±o del texto en el eje X
  las         = 2,                        # rota las etiquetas del eje X (vertical)
  gap         = 3,                        # espacio entre barras
  combined    = FALSE,                    # muestra el barplot separado para cada variable
  ylab        = c("Proporci√≥n de datos",  # etiquetas del eje Y
                  "Datos faltantes")
)
```

La Figura \@ref(fig:vis-missing) muestra el patr√≥n espacial de datos faltantes.

```{r vis-missing, fig.width=12, fig.height=6, fig.cap="Mapa de valores faltantes. Columnas gris indican presencia de dato, negra indica ausencia.", echo=FALSE}
vis_miss(datos_limpios, sort_miss = TRUE) 
```


La revisi√≥n conjunta de las Figuras \@ref(fig:fig-datos-faltantes) y \@ref(fig:vis-missing), junto con las Tablas \@ref(tab:tabla-nulos-original), \@ref(tab:tabla-nulos-sin-duplicados) y \@ref(tab:tabla-nulos), confirma que el problema de datos faltantes es reducido y est√° concentrado exclusivamente en las variables 
**Income** y **MntWines**. En el dataset original se observan 68 valores faltantes en **Income` (3.06%)** y **20** en **MntWines (0.90%)**. Tras eliminar duplicados, las proporciones se mantienen pr√°cticamente inalteradas (**3.33\%** y **0.98\%**, respectivamente). Finalmente, en el conjunto depurado sin duplicados ni inconsistencias, **Income** presenta **66** valores faltantes (**3.25\%**) y **MntWines** presenta **20** (**0.99\%**). 

Las Figuras \@ref(fig:fig-datos-faltantes) y \@ref(fig:vis-missing) muestran que el resto de variables no presentan ausencia de datos y que los faltantes aparecen de forma espor√°dica y dispersa, sin aparente evidencia de patrones estructurados ni bloques sistem√°ticos de coausencia. Dado que todas las proporciones est√°n por debajo del umbral del **5\%** se√±alado en la literatura especializada  (Little y Rubin, 2002), el nivel de datos faltantes puede considerarse bajo y su impacto potencial sobre los an√°lisis posteriores es limitado y manejable mediante procedimientos est√°ndar de tratamiento de valores ausentes.


## Tratamiento de Datos Faltantes

### Evaluaci√≥n del mecanismo generador de datos faltantes

Para evaluar si los datos faltan completamente al azar (MCAR), se aplica el test de Little (1988) considerando un conjunto amplio de variables que podr√≠an estar relacionadas con la probabilidad de missing. Se incluyen: ingresos, gasto en vinos, edad, n√∫mero de hijos, antig√ºedad, frecuencia de compras y variables demogr√°ficas codificadas como factores.

```{r test-mca, echo=FALSE}
## Reconstruir variables categ√≥ricas originales a partir de dummies
datos_little <- datos_limpios %>%
  mutate(
    Education = case_when(
      education_PhD == 1 ~ "PhD",
      education_Master == 1 ~ "Master",
      education_Graduation == 1 ~ "Graduation",
      education_Basic == 1 ~ "Basic",
      `education_2n Cycle` == 1 ~ "2n Cycle",
      TRUE ~ NA_character_
    ),
    Marital = case_when(
      marital_Divorced == 1 ~ "Divorced",
      marital_Married == 1 ~ "Married",
      marital_Single == 1 ~ "Single",
      marital_Together == 1 ~ "Together",
      marital_Widow == 1 ~ "Widow",
      TRUE ~ NA_character_
    )
  ) %>%
  select(Income, MntWines, Age, Kidhome, Teenhome, Recency,
         NumWebPurchases, NumStorePurchases, NumCatalogPurchases,
         Education, Marital)

# Convertir a factores
datos_little$Education <- factor(datos_little$Education)
datos_little$Marital <- factor(datos_little$Marital)

# Aplicar test de Little
test_little <- mcar_test(datos_little)

knitr::kable(
  data.frame(
    Estad√≠stico = test_little$statistic,
    gl = test_little$df,
    p_valor = test_little$p.value
  ),
  caption = "Test de Little para MCAR (con variables relevantes)",
  digits = 4
)
```


La Tabla \@ref(tab:test-mca) muestra el resultado al aplicar el test de Little (1988) para evaluar si los datos faltantes siguen un mecanismo **MCAR (Missing Completely At Random)**.

**Hip√≥tesis:**

$$H_0: \text{Los datos faltantes son MCAR (completamente al azar)}$$
$$H_1: \text{Los datos faltantes NO son MCAR (dependen de otras variables)}$$




Dado que el p-valor = `r round(test_little$p.value, 4)` < 0.05, se rechaza $H_{0}$. En consecuencia, los datos no siguen un mecanismo completamente aleatorio (**MCAR**). No obstante, dado el bajo porcentaje de ausencia (**<5%**) y la ausencia de evidencia estructural de **MNAR (Missing Not At Random)**, se asume razonablemente un mecanismo **MAR (Missing At Random)** para efectos de imputaci√≥n m√∫ltiple.


Bajo **MAR**, la eliminaci√≥n por lista completa puede inducir sesgo y p√©rdida innecesaria de eficiencia. Por ello se emplea imputaci√≥n m√∫ltiple seg√∫n Rubin (1987), que:

- Preserva la estructura multivariada.

- Incorpora la incertidumbre de imputaci√≥n.

- Mantiene la variabilidad poblacional.



Se excluyen variables que constituyen combinaciones lineales exactas (por ejemplo, **MntTotal**, **MntRegularProds** y **AcceptedCmpOverall**), ya que generan multicolinealidad perfecta y matrices singulares en el algoritmo de imputaci√≥n (criterio cl√°sico de diagn√≥stico estructural). Las variables derivadas se recalculan posteriormente.

```r
# Colinealidad perfecta (VIF = ‚àû)
- MntTotal = MntWines + MntFruits + MntMeatProducts + MntFishProducts + MntSweetProducts
- MntRegularProds = MntTotal ‚àí MntGoldProds
- AcceptedCmpOverall = AcceptedCmp1 + AcceptedCmp2 + AcceptedCmp3 + AcceptedCmp4 + AcceptedCmp5
```

```{r eliminar-redundante, echo=FALSE}
datos_imputacion <- datos_limpios %>%
  select(-MntRegularProds, -MntTotal, -AcceptedCmpOverall)
```


Se comparan tres m√©todos: **PMM (Predictive Mean Matching)** con regularizaci√≥n ridge, **CART (Classification and Regression Trees)** y **Regresi√≥n ridge**
Con **m=5** imputaciones y 10 iteraciones.

```{r, echo=FALSE}
vars_predictoras <- c(
  "Age", "Customer_Days", "Recency",
  "NumWebPurchases", "NumCatalogPurchases", "NumStorePurchases",
  "NumWebVisitsMonth", "NumDealsPurchases",
  "Kidhome", "Teenhome",
  "marital_Married", "marital_Single",
  "education_Graduation", "education_Master", "education_PhD",
  "MntMeatProducts", "MntWines", "Income"
)

datos_imp_subset <- datos_imputacion %>%
  select(all_of(vars_predictoras))

# PMM con ridge
imp_pmm <- mice(datos_imp_subset, m = 5, method = "pmm",
                ridge = 1e-4, maxit = 10, seed = 42, printFlag = FALSE)

# CART
imp_cart <- mice(datos_imp_subset, m = 5, method = "cart",
                 maxit = 10, seed = 42, printFlag = FALSE)

# Regresi√≥n Ridge
metodos <- make.method(datos_imp_subset)
metodos["Income"] <- "norm"
metodos["MntWines"] <- "norm"
predictor_matrix <- make.predictorMatrix(datos_imp_subset)
diag(predictor_matrix) <- 0

imp_ridge <- mice(datos_imp_subset, m = 5, method = metodos,
                  predictorMatrix = predictor_matrix,
                  ridge = 1e-3, maxit = 10, seed = 42, printFlag = FALSE)
```


Para elegir el m√©todo que mejor preserva la estructura de los datos observados, se eval√∫an:

1. Estabilidad de las imputaciones: desviaci√≥n est√°ndar de las medias imputadas entre las 5 r√©plicas.

2. Preservaci√≥n de momentos: comparaci√≥n de medias y varianzas de las variables imputadas con las observadas (listwise deletion).

3. Preservaci√≥n de correlaciones: comparaci√≥n de la matriz de correlaci√≥n de las variables clave (Income, MntWines, Age, MntTotal) con la observada.

Los resultados se presentan en la Tabla \@ref(tab:comp-metd-imputacion).

```{r comp-metd-imputacion, echo=FALSE}
# Funci√≥n para extraer estad√≠sticos de un objeto mice
estadisticos_imputacion <- function(imp, metodo_nombre) {
  completed <- complete(imp, "long")
  stats_income <- completed %>%
    group_by(.imp) %>%
    summarise(media_income = mean(Income, na.rm = TRUE),
              sd_income = sd(Income, na.rm = TRUE)) %>%
    ungroup() %>%
    summarise(media_media = mean(media_income),
              sd_media = sd(media_income),
              media_sd = mean(sd_income))
  
  stats_wines <- completed %>%
    group_by(.imp) %>%
    summarise(media_wines = mean(MntWines, na.rm = TRUE),
              sd_wines = sd(MntWines, na.rm = TRUE)) %>%
    ungroup() %>%
    summarise(media_media_w = mean(media_wines),
              sd_media_w = sd(media_wines),
              media_sd_w = mean(sd_wines))
  
  data.frame(
    Metodo = metodo_nombre,
    Income_media = stats_income$media_media,
    Income_sd = stats_income$media_sd,
    Income_sd_entre = stats_income$sd_media,
    MntWines_media = stats_wines$media_media_w,
    MntWines_sd = stats_wines$media_sd_w,
    MntWines_sd_entre = stats_wines$sd_media_w
  )
}

# Estad√≠sticos observados
obs_stats <- datos_imp_subset %>%
  filter(!is.na(Income) & !is.na(MntWines)) %>%
  summarise(
    Income_media_obs = mean(Income),
    Income_sd_obs = sd(Income),
    MntWines_media_obs = mean(MntWines),
    MntWines_sd_obs = sd(MntWines)
  )

# Aplicar a cada m√©todo
comp_metodos <- bind_rows(
  estadisticos_imputacion(imp_pmm, "PMM"),
  estadisticos_imputacion(imp_cart, "CART"),
  estadisticos_imputacion(imp_ridge, "Ridge")
)

# A√±adir diferencias relativas
comp_metodos <- comp_metodos %>%
  mutate(
    Income_diff_media = abs(Income_media - obs_stats$Income_media_obs) / obs_stats$Income_media_obs * 100,
    Income_diff_sd = abs(Income_sd - obs_stats$Income_sd_obs) / obs_stats$Income_sd_obs * 100,
    Wines_diff_media = abs(MntWines_media - obs_stats$MntWines_media_obs) / obs_stats$MntWines_media_obs * 100,
    Wines_diff_sd = abs(MntWines_sd - obs_stats$MntWines_sd_obs) / obs_stats$MntWines_sd_obs * 100
  )

knitr::kable(comp_metodos, digits = 2, format = "html",
             caption = "Comparaci√≥n de m√©todos de imputaci√≥n")
```

Adicionalmente en la Tabla \@ref(tab:tabla-cor), se comparan las correlaciones de Pearson entre Income, MntWines y Age para cada m√©todo (promedio de las 5 imputaciones) frente a la correlaci√≥n observada.


```{r tabla-cor, echo=FALSE}
# Correlaci√≥n observada
obs_cor <- datos_imp_subset %>%
  filter(!is.na(Income) & !is.na(MntWines)) %>%
  select(Income, MntWines, Age) %>%
  cor(use = "complete.obs")

# Funci√≥n para correlaciones promedio de un m√©todo
cor_method <- function(imp) {
  completed <- complete(imp, "long")
  cors <- completed %>%
    group_by(.imp) %>%
    summarise(cor_inc_wine = cor(Income, MntWines, use = "complete.obs"),
              cor_inc_age = cor(Income, Age, use = "complete.obs"),
              cor_wine_age = cor(MntWines, Age, use = "complete.obs")) %>%
    ungroup() %>%
    summarise(across(starts_with("cor"), mean))
  as.numeric(cors)
}

cor_pmm <- cor_method(imp_pmm)
cor_cart <- cor_method(imp_cart)
cor_ridge <- cor_method(imp_ridge)

tabla_cor <- data.frame(
  Metodo = c("Observado", "PMM", "CART", "Ridge"),
  rbind(
    c(obs_cor["Income","MntWines"], obs_cor["Income","Age"], obs_cor["MntWines","Age"]),
    cor_pmm,
    cor_cart,
    cor_ridge
  )
)
names(tabla_cor)[2:4] <- c("Income~MntWines", "Income~Age", "MntWines~Age")

knitr::kable(tabla_cor, digits = 3,
             caption = "Comparaci√≥n de correlaciones promedio (5 imputaciones) con las observadas.")
```


Basado en la menor diferencia relativa de medias y desviaciones, as√≠ como la preservaci√≥n de correlaciones, se selecciona **PMM** con ridge como m√©todo final (van Buuren, 2018, Flexible Imputation of Missing Data). Este m√©todo presenta la mayor estabilidad (baja desviaci√≥n entre imputaciones) y reproduce fielmente la estructura correlacional.


Se utiliza la primera imputaci√≥n de *PMM* para el an√°lisis descriptivo, previa verificaci√≥n de que las 5 imputaciones producen resultados muy similares (Tabla \@ref(tab:consistencia-imputaciones).

```{r consistencia-imputaciones, echo=FALSE}
# Mostrar variabilidad de medias entre imputaciones PMM
completed_pmm <- complete(imp_pmm, "long")
medias_por_imp <- completed_pmm %>%
  group_by(.imp) %>%
  summarise(media_income = mean(Income),
            media_wines = mean(MntWines))
knitr::kable(medias_por_imp, digits = 2,
             caption = "Medias de Income y MntWines en cada una de las 5 imputaciones (PMM). La baja variabilidad confirma estabilidad.")
```

```{r, echo=FALSE}
# Tomar primera imputaci√≥n
datos_final_subset <- complete(imp_pmm, 1)

# Reconstruir dataset completo
datos_final <- datos_imputacion
datos_final$Income <- datos_final_subset$Income
datos_final$MntWines <- datos_final_subset$MntWines

# Recalcular variables derivadas
datos_final <- datos_final %>%
  mutate(
    MntTotal = MntWines + MntFruits + MntMeatProducts + 
               MntFishProducts + MntSweetProducts + MntGoldProds,
    MntRegularProds = MntFruits + MntMeatProducts + MntFishProducts + MntSweetProducts,
    AcceptedCmpOverall = pmax(AcceptedCmp1, AcceptedCmp2, AcceptedCmp3, 
                              AcceptedCmp4, AcceptedCmp5)
  )
```


Para la validaci√≥n estructural post-imputaci√≥n, se comparan densidades antes y despu√©s de imputar como se ne la Figura \@ref(fig:densidad-compa).

```{r densidad-compa, echo=FALSE, fig.cap="Densidades originales vs imputadas para Income y MntWines.", fig.width=12}
p1 <- ggplot() +
  geom_density(data = datos_limpios, aes(x = Income, color = "Original (con NA)"), 
               linewidth = 1, na.rm = TRUE) +
  geom_density(data = datos_final, aes(x = Income, color = "Imputado"), 
               linewidth = 1, linetype = "dashed") +
  scale_color_manual(
    name = "Datos",
    values = c("Original (con NA)" = "red", "Imputado" = "blue")
  ) +
  labs(
    title = "Income: Original (con NA) vs Imputado",
    x = "Ingreso anual", y = "Densidad"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 10),   # reduce tama√±o para que no se corte
    legend.position = "bottom"
  )

p2 <- ggplot() +
  geom_density(data = datos_limpios, aes(x = MntWines, color = "Original"), 
               linewidth = 1, na.rm = TRUE) +
  geom_density(data = datos_final, aes(x = MntWines, color = "Imputado"), 
               linewidth = 1, linetype = "dashed") +
  scale_color_manual(
    name = "Datos",
    values = c("Original" = "red", "Imputado" = "blue")
  ) +
  labs(
    title = "MntWines: Original vs Imputado",
    x = "Monto en vinos", y = "Densidad"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

grid.arrange(p1, p2, ncol = 2)
```

Las curvas muestran superposici√≥n casi completa, sin distorsi√≥n visible. Finalmente, se analiza la matriz de correlaciones en la Figura \@ref(fig:matriz-cor).

```{r matriz-cor, echo=FALSE, fig.cap="Matriz de correlaciones de variables num√©ricas."}
vars_cor <- c("Income", "MntWines", "MntMeatProducts", "MntFishProducts",
              "MntFruits", "MntSweetProducts", "MntGoldProds",
              "NumWebPurchases", "NumCatalogPurchases", "NumStorePurchases",
              "Age", "Recency", "Customer_Days")

cor_matrix <- cor(datos_final[, vars_cor], use = "complete.obs")

corrplot(cor_matrix, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45,
         addCoef.col = "black",      # Color de los coeficientes
         number.cex = 0.7,            # Tama√±o del texto
         number.digits = 2,           # Decimales
         title = "Matriz de correlaciones de variables num√©ricas",
         mar = c(0,0,2,0))
```

Las relaciones esperadas (por ejemplo, alta correlaci√≥n entre Income y MntWines) se mantienen, lo que confirma preservaci√≥n estructural. Tambi√©n, correlaciones moderadas entre distintos tipos de gasto, indicando cierto patr√≥n de consumo conjunto. Adem√°s, se rsalta que la variable Recency presenta correlaciones bajas con el resto, sugiriendo independencia.



